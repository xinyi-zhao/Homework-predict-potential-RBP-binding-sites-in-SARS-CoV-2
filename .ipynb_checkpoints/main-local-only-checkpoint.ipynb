{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "from gensim.models import doc2vec\n",
    "import os.path as osp\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn,optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from embeddings_reproduction import embedding_tools\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "file_dir='data/'\n",
    "task='C17ORF85_Baltz2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_kmers(seq, k=3, overlap=False, **kwargs):\n",
    "    N = len(seq)\n",
    "    if overlap:\n",
    "        return [[seq[i:i+k] for i in range(N - k + 1)]]\n",
    "    else:\n",
    "        return [[seq[i:i+k] for i in range(j, N - k + 1, k)]\n",
    "                for j in range(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(doc2vec_file,seq, k=5, overlap=False, norm=True, steps=5):\n",
    "    \"\"\" Infer embeddings in one pass using a gensim doc2vec model.\n",
    "\n",
    "    Parameters:\n",
    "        doc2vec_file (str): file pointing to saved doc2vec model\n",
    "        seqs (iterable): sequences to infer\n",
    "        k (int) default 3\n",
    "        overlap (Boolean) default False\n",
    "        norm (Boolean) default True\n",
    "        steps (int): number of steps during inference. Default 5.\n",
    "\n",
    "    Returns:\n",
    "        numpy ndarray where each row is the embedding for one sequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    as_kmer = []+seq_to_kmers(seq, k=k, overlap=overlap)\n",
    "    as_kmer=as_kmer[0]\n",
    "    model = doc2vec.Doc2Vec.load(doc2vec_file)\n",
    "    #print(as_kmer[0])\n",
    "    vector_ret=model.infer_vector(as_kmer, steps=steps)\n",
    "    return vector_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bases = ['A', 'C', 'G', 'U']\n",
    "base_dict = {'A': 0, 'C': 1, 'G': 2, 'U': 3}\n",
    "bases_len = len(bases)\n",
    "num_feature = 271 #total number of features\n",
    "def convert_to_index(str,word_len):\n",
    "    output_index = 0\n",
    "    for i in range(word_len):\n",
    "        output_index = output_index * bases_len + base_dict[str[i]]\n",
    "    return output_index\n",
    "\n",
    "def extract_features(line):\n",
    "    line2=line\n",
    "    for i in 'agctu\\n':\n",
    "        line2 = line2.replace(i, '')\n",
    "    line = line.upper().rstrip()\n",
    "    line = line.replace('T', 'U')\n",
    "    line2 = line2.replace('T','U')\n",
    "   #line = line.replace('N','')\n",
    "   #line2 = line2.replace('N','')\n",
    "    final_output=[]#get_embeddings('outputs/docvec_models/2_virus_5_6.pkl',line).tolist()\n",
    "    final_output.extend(get_embeddings('outputs/docvec_models/0_virus_5_6.pkl',line2).tolist())\n",
    "    for word_len in [1,2,3]:\n",
    "        output_count_list = [0 for i in range(bases_len ** word_len)]\n",
    "        for i in range(len(line) - word_len + 1):\n",
    "            output_count_list[convert_to_index(line[i: i + word_len],word_len)] += 1\n",
    "        output_count_list2 = [0 for i in range(bases_len ** word_len)]\n",
    "        for i in range(len(line2)-word_len+1):\n",
    "            output_count_list2[convert_to_index(line2[i:i+word_len],word_len)] +=1\n",
    "        final_output.extend(output_count_list)\n",
    "        final_output.extend(output_count_list2)\n",
    "    for word_len in [4,5,6]:\n",
    "        output_count_list = [0 for i in range(bases_len ** 2)]\n",
    "        for i in range(len(line) - word_len):\n",
    "            output_count_list[convert_to_index(line[i]+line[i + word_len],2)] += 1\n",
    "        output_count_list2 = [0 for i in range(bases_len ** 2)]\n",
    "        for i in range(len(line2)-word_len):\n",
    "              output_count_list2[convert_to_index(line2[i]+line2[i+word_len],2)] +=1\n",
    "        final_output.extend(output_count_list)\n",
    "        final_output.extend(output_count_list2)\n",
    "    final_output.append(len(line2))\n",
    "    final_output.append(math.log(len(line2)))\n",
    "    final_output.append(int(len(line2) % 3 == 0))\n",
    "    stop_codons = ['UAG', 'UAA', 'UGA']\n",
    "    stop_codon_features = [0,0,0,0]\n",
    "    for stop_codon_num in range(len(stop_codons)):\n",
    "        tmp_arr = [m.start() for m in re.finditer(stop_codons[stop_codon_num], line2)]\n",
    "        tmp_arr_div3 = [i for i in tmp_arr if i % 3 == 0]\n",
    "        stop_codon_features[stop_codon_num]=int(len(tmp_arr_div3) > 0)\n",
    "        stop_codon_features[3]|=stop_codon_features[stop_codon_num]\n",
    "    final_output.extend(stop_codon_features)\n",
    "    return final_output\n",
    "\n",
    "\n",
    "def load_dataset(task,is_load):\n",
    "    x_train=[]\n",
    "    x_valid=[]\n",
    "    x_test=[]\n",
    "    y_train=[]\n",
    "    y_valid=[]\n",
    "    y_test=[]\n",
    "    N=0\n",
    "    filename=file_dir+task+'.train.positives.fa'\n",
    "    for line in open(filename, \"r\"):\n",
    "        if line[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            if ('n' in line or 'N' in line):\n",
    "                continue\n",
    "            else:\n",
    "                N+=1\n",
    "    select_list = list(range(N))\n",
    "    valid_set=random.sample(select_list,(int)(N/10))\n",
    "    filename=file_dir+task+'.train.positives.fa'\n",
    "    num=0\n",
    "    for line in open(filename, \"r\"):\n",
    "        if line[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            if ('n' in line or 'N' in line):\n",
    "                continue\n",
    "            else:\n",
    "                num+=1\n",
    "                if(num in valid_set):\n",
    "                    x_valid.append(extract_features(line.strip('\\n').strip('\\r')))\n",
    "                    y_valid.append(1.0)\n",
    "                else:\n",
    "                    x_train.append(extract_features(line.strip('\\n').strip('\\r')))\n",
    "                    y_train.append(1.0)\n",
    "                    \n",
    "                \n",
    "    filename=file_dir+task+'.train.negatives.fa'\n",
    "    num=0\n",
    "    for line in open(filename, \"r\"):\n",
    "        if line[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            if ('n' in line or 'N' in line):\n",
    "                continue\n",
    "            else:\n",
    "                num+=1\n",
    "                if(num in valid_set):\n",
    "                    x_valid.append(extract_features(line.strip('\\n').strip('\\r')))\n",
    "                    y_valid.append(0)\n",
    "                else:\n",
    "                    x_train.append(extract_features(line.strip('\\n').strip('\\r')))\n",
    "                    y_train.append(0)\n",
    "                    \n",
    "    filename=file_dir+task+'.ls.positives.fa'\n",
    "    for line in open(filename, \"r\"):\n",
    "        if line[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            if ('n' in line or 'N' in line):\n",
    "                continue\n",
    "            else:\n",
    "                x_test.append(extract_features(line.strip('\\n').strip('\\r')))\n",
    "                y_test.append(1.0)\n",
    "    filename=file_dir+task+'.ls.negatives.fa'\n",
    "    for line in open(filename, \"r\"):\n",
    "        if line[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            if ('n' in line or 'N' in line):\n",
    "                continue\n",
    "            else:\n",
    "                x_test.append(extract_features(line.strip('\\n').strip('\\r')))\n",
    "                y_test.append(0)\n",
    "    return np.array(x_train),np.array(y_train),np.array(x_valid),np.array(y_valid),np.array(x_test),np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2170, 335)\n",
      "(2170,)\n",
      "(240, 335)\n",
      "(240,)\n",
      "(266, 335)\n",
      "(266,)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid,x_test,y_test=load_dataset(task,is_load=False)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "x_train=torch.from_numpy(x_train).float()\n",
    "y_train=torch.from_numpy(y_train).float()\n",
    "\n",
    "x_valid=torch.from_numpy(x_valid).float()\n",
    "y_valid=torch.from_numpy(y_valid).float()\n",
    "\n",
    "x_test=torch.from_numpy(x_test).float()\n",
    "y_test=torch.from_numpy(y_test).float()\n",
    "\n",
    "y_train = y_train.unsqueeze(1)\n",
    "y_test = y_test.unsqueeze(1)\n",
    "y_valid = y_valid.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-4\n",
    "feature_num=335\n",
    "class nnNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, out_dim):\n",
    "        super(nnNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1))\n",
    "        self.layer2=nn.Sequential(nn.Linear(n_hidden_1, n_hidden_1))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_1, out_dim))\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer3(x)\n",
    "        return torch.sigmoid(x)\n",
    "model=nnNet(feature_num,64,1)\n",
    "criterion =nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=10 ** (-5.0))\n",
    "\n",
    "num_epoch=5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7044891119003296 0.5571435367353735 0.49149246475449676\n",
      "0.6878293752670288 0.5657127736209369 0.4990624348913119\n",
      "0.6812427639961243 0.5704091826540807 0.5039933328703382\n",
      "0.6788443326950073 0.5743627121178141 0.5067018542954372\n",
      "0.6772264838218689 0.5776723276723277 0.5080213903743315\n",
      "0.6760063171386719 0.5803499221866569 0.5117022015417737\n",
      "0.6749605536460876 0.5829960855471059 0.5128828390860476\n",
      "0.6739919781684875 0.585484243647509 0.5156608097784569\n",
      "0.6730471849441528 0.5881805269560372 0.5178831863323842\n",
      "0.6720945835113525 0.5908963485494099 0.5206611570247934\n",
      "0.6711150407791138 0.5939035454341577 0.5237169247864435\n",
      "0.6701003313064575 0.5971757834002731 0.5271199388846448\n",
      "0.6690506935119629 0.6006366082896695 0.5306618515174665\n",
      "0.6679648756980896 0.6047260562566685 0.5357316480311133\n",
      "0.6668334603309631 0.609072050398581 0.5412181401486215\n",
      "0.6656408905982971 0.6141129278884381 0.5466351829988194\n",
      "0.6643772125244141 0.6199412832065894 0.5521216751163276\n",
      "0.6630275845527649 0.626721917538244 0.5612889784012779\n",
      "0.6615769267082214 0.6347980251041476 0.5689978470727134\n",
      "0.6600873470306396 0.6440260419852257 0.5785818459615252\n",
      "0.6586499214172363 0.6529125636268494 0.5873324536426141\n",
      "0.6572529077529907 0.6602462163686653 0.5939301340370859\n",
      "0.655892014503479 0.666970784317723 0.6020556983123829\n",
      "0.6545603275299072 0.6743503095543912 0.6092089728453365\n",
      "0.6532394886016846 0.6823941364757691 0.6199736092784222\n",
      "0.6519252061843872 0.6907905020149918 0.630182651573026\n",
      "0.6506232619285583 0.6992182987080946 0.6376831724425307\n",
      "0.6493515968322754 0.7071126152758807 0.6476144176678936\n",
      "0.6481311917304993 0.7149049929662175 0.6593513438433225\n",
      "0.6469749212265015 0.7218130508946835 0.669490936870616\n",
      "0.6458878517150879 0.7278648222525773 0.6783804430863255\n",
      "0.6448661684989929 0.7331962255431643 0.6859504132231405\n",
      "0.6439017653465271 0.7378403909016154 0.690047919994444\n",
      "0.6429838538169861 0.742041122143163 0.6964372525869852\n",
      "0.6421037316322327 0.7459258428646183 0.7001875130217377\n",
      "0.6412541270256042 0.7494750147811372 0.7053962080700048\n",
      "0.6404282450675964 0.7526393674352858 0.7075491353566221\n",
      "0.6396219730377197 0.755605788769054 0.7110910479894437\n",
      "0.6388312578201294 0.7581364214017275 0.715396902562678\n",
      "0.6380542516708374 0.760671301487628 0.7173414820473645\n",
      "0.6372902393341064 0.7628672348060103 0.7189388151954996\n",
      "0.636539876461029 0.7649935098914691 0.7206750468782555\n",
      "0.6358036994934082 0.7667978280223178 0.7234530175706647\n",
      "0.6350832581520081 0.768513799126044 0.724494756580318\n",
      "0.6343792676925659 0.770217027870089 0.725953191193833\n",
      "0.6336910128593445 0.7718302106057208 0.7272032780054171\n",
      "0.6330181360244751 0.773429801491026 0.7297034516285854\n",
      "0.6323586702346802 0.7748968718356473 0.730536842836308\n",
      "0.6317121982574463 0.7761991409950595 0.7313007847767207\n",
      "0.6310798525810242 0.7774334509028387 0.7321341759844434\n",
      "0.6304640173912048 0.7785063575879902 0.731995277449823\n",
      "0.6298671364784241 0.7795860601983051 0.7326897701229252\n",
      "0.6292878985404968 0.7805052090766376 0.7335926105979582\n",
      "0.6287251114845276 0.7814294548988426 0.7340093062018196\n",
      "0.6281765103340149 0.7823358614174941 0.7349815959441629\n",
      "0.6276402473449707 0.783181104609676 0.7351899437460936\n",
      "0.6271145939826965 0.7839923681760417 0.7352593930134038\n",
      "0.6265982389450073 0.784824019517897 0.7353288422807139\n",
      "0.6260902881622314 0.7856454769720076 0.735606639349955\n",
      "0.6255889534950256 0.7863335643947889 0.7363011320230571\n",
      "0.6250942349433899 0.7870420395930601 0.7372039724980901\n",
      "0.6246058344841003 0.7876426294793641 0.737759566636572\n",
      "0.6241238117218018 0.788213487193079 0.7382457115077435\n",
      "0.6236497163772583 0.7887639571313039 0.7381762622404333\n",
      "0.6231842637062073 0.7893093301256566 0.7380373637058129\n",
      "0.6227287650108337 0.7897663560928868 0.7376206681019515\n",
      "0.622283935546875 0.790024601249091 0.7374817695673311\n",
      "0.6218500733375549 0.7902879433491677 0.7370650739634698\n",
      "0.6214278936386108 0.7904807777256757 0.7371345232307799\n",
      "0.6210160255432129 0.7906931503870278 0.7364400305576776\n",
      "0.6206145882606506 0.7908384132873929 0.7369956246961594\n",
      "0.6202229857444763 0.7909883483863076 0.736578929092298\n",
      "0.6198402643203735 0.7911527248261943 0.7358149871518855\n",
      "0.6194661855697632 0.7912606101381612 0.7360233349538162\n",
      "0.619100034236908 0.7914152174356256 0.7360927842211265\n",
      "0.6187409162521362 0.7914797787246766 0.7358149871518855\n",
      "0.6183886528015137 0.7915579318640544 0.7355371900826447\n",
      "0.618042528629303 0.7916853554608657 0.7356760886172651\n",
      "0.6177021861076355 0.7917558631844346 0.7353982915480243\n",
      "0.6173673272132874 0.7918926311783454 0.7349121466768526\n",
      "0.6170374751091003 0.791953794504815 0.7340787554691299\n",
      "0.616712212562561 0.7920429910225828 0.7339398569345094\n",
      "0.6163919568061829 0.7921330370309961 0.7342176540037504\n",
      "0.6160761117935181 0.7922264810019911 0.7339398569345094\n",
      "0.6157644987106323 0.792282972129911 0.7342871032710605\n",
      "0.6154571175575256 0.7923657974678382 0.7338009583998889\n",
      "0.6151538491249084 0.7923904326965551 0.7336620598652683\n",
      "0.6148544549942017 0.7924736827798053 0.7340093062018196\n",
      "0.6145588755607605 0.7924906725927134 0.7338009583998889\n",
      "0.6142668724060059 0.7925475884659559 0.73414820473644\n",
      "0.6139801740646362 0.7925348461062747 0.7342176540037503\n",
      "0.6136981844902039 0.7925301739077251 0.7346343496076118\n",
      "0.6134299039840698 0.7925802938558041 0.7346343496076116\n",
      "0.6131584644317627 0.7925994073953258 0.7345649003403014\n",
      "0.612892210483551 0.7926966740742251 0.7345649003403014\n",
      "0.6126286387443542 0.7927094164339061 0.7343565525383707\n",
      "0.6123678684234619 0.7927799241574752 0.7340787554691298\n",
      "0.6121114492416382 0.7928427864652354 0.7338009583998889\n",
      "0.611857533454895 0.7928712444018566 0.7338009583998889\n",
      "0.6116061210632324 0.7929115952075135 0.733523161330648\n",
      "0.6113573908805847 0.7929544944851066 0.7337315091325787\n",
      "0.6111134886741638 0.7929443005973618 0.7338009583998888\n",
      "0.6110039353370667 0.7930194805194806 0.7340787554691298\n",
      "0.6106358766555786 0.7929663873541425 0.7340093062018196\n",
      "0.6104168891906738 0.792957042957043 0.7342871032710605\n",
      "0.6101848483085632 0.7929413273801029 0.7347037988749219\n",
      "0.6099563837051392 0.7929765812418874 0.7348426974095423\n",
      "0.6097350716590881 0.7929978185080225 0.7348426974095423\n",
      "0.6095159649848938 0.7930233032273848 0.735051045211473\n",
      "0.6092989444732666 0.7930139588302854 0.7356760886172652\n",
      "0.6090843677520752 0.7930373198230342 0.7353288422807139\n",
      "0.60887211561203 0.7930054639238312 0.7360927842211266\n",
      "0.6086621880531311 0.7929549192304295 0.7363011320230571\n",
      "0.6084920167922974 0.7929345314549396 0.7363011320230571\n",
      "0.6084043979644775 0.7930466642201336 0.7365094798249878\n",
      "0.6081109642982483 0.7930228784820621 0.7365789290922982\n",
      "0.6078806519508362 0.7930135340849627 0.7366483783596083\n",
      "0.6076910495758057 0.7930080123957675 0.736578929092298\n",
      "0.60750812292099 0.7930033401972179 0.736856726161539\n",
      "0.6073263883590698 0.7930084371410902 0.7369261754288492\n",
      "0.6071467399597168 0.7930377445683569 0.737169247864435\n",
      "0.6069691181182861 0.7930334971151298 0.7367178276269185\n",
      "0.6067933440208435 0.7930356208417433 0.7367178276269186\n",
      "0.6066192984580994 0.7929838019123733 0.7369261754288492\n",
      "0.6064469218254089 0.792931133492358 0.7366483783596083\n",
      "0.6062763929367065 0.7929243375671946 0.7364400305576776\n",
      "0.6061071753501892 0.7928708196565339 0.7364400305576777\n",
      "0.6059398055076599 0.7928427864652353 0.7364400305576777\n",
      "0.60577392578125 0.7928173017458733 0.7364400305576775\n",
      "0.6056098341941833 0.7927909675358655 0.7367178276269186\n",
      "0.6055952310562134 0.7927544394381127 0.7366483783596083\n",
      "0.6053417921066284 0.7928257966523273 0.7369261754288493\n",
      "0.6051589846611023 0.7928181512365187 0.7367525522605737\n",
      "0.6049949526786804 0.7928466091731399 0.7367872768942288\n",
      "0.6048420071601868 0.7928291946149089 0.7367178276269186\n",
      "0.6046925187110901 0.7928011614236103 0.7369261754288492\n",
      "0.604543924331665 0.7927875695732838 0.7367872768942287\n",
      "0.6043972969055176 0.792754439438113 0.7367178276269185\n",
      "0.6042516827583313 0.7927574126553718 0.7369261754288492\n",
      "0.604107141494751 0.7927603858726309 0.7369261754288492\n",
      "0.6039631962776184 0.7927493424942404 0.7373428710327106\n",
      "0.6038200855255127 0.7927344764079458 0.7374817695673311\n",
      "0.6036778092384338 0.7926915771303527 0.7377942912702271\n",
      "0.6035362482070923 0.7926949750929342 0.7378290159038823\n",
      "0.603395402431488 0.7926852059505121 0.7378290159038823\n",
      "0.6032811403274536 0.7926563232685682 0.7380026390721578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6031242609024048 0.7927055937260019 0.7379331898048476\n",
      "0.603003203868866 0.7926677913922812 0.7379679144385027\n",
      "0.602870762348175 0.7926818079879305 0.738349885408709\n",
      "0.6027323007583618 0.7926660924109903 0.7381068129731232\n",
      "0.6025967001914978 0.7926359354930784 0.7381068129731232\n",
      "0.6024681925773621 0.7926274405866244 0.7382109868740885\n",
      "0.6023394465446472 0.7925943104514533 0.7378984651711925\n",
      "0.602212131023407 0.7926121497550068 0.7384193346760192\n",
      "0.6020850539207458 0.792606203320489 0.7385929578442948\n",
      "0.6019587516784668 0.7925437657580514 0.7388360302798807\n",
      "0.601832926273346 0.7925063881696535 0.7392180012500869\n",
      "0.6017078161239624 0.7924860003941637 0.7392180012500869\n",
      "0.6015832424163818 0.7924821776862594 0.7394263490520175\n",
      "0.601471483707428 0.792471134307869 0.7396694214876034\n",
      "0.6014233827590942 0.7924779302330323 0.7397388707549135\n",
      "0.601273238658905 0.7924588166935106 0.7397041461212586\n",
      "0.601105272769928 0.7924086967454314 0.739843044655879\n",
      "0.6009917259216309 0.7923640984865475 0.7399472185568443\n",
      "0.6008758544921875 0.792359001542675 0.7399472185568443\n",
      "0.6007593274116516 0.79233309207799 0.7396694214876033\n",
      "0.6006453633308411 0.7922723534968434 0.7396346968539482\n",
      "0.600532054901123 0.7922328521818318 0.7396346968539482\n",
      "0.6004191637039185 0.7922001467919836 0.7398083200222237\n",
      "0.6003066897392273 0.7921840064697208 0.7397735953885687\n",
      "0.6001949310302734 0.7921691403834261 0.7400166678241544\n",
      "0.6000834107398987 0.7921742373272984 0.7397041461212585\n",
      "0.5999777317047119 0.7921419566827731 0.7397388707549135\n",
      "0.6000930070877075 0.7920748469217856 0.7402250156260852\n",
      "0.5997607111930847 0.7920986326598571 0.7401555663587749\n",
      "0.5996792912483215 0.7920655025246862 0.7400513924578096\n",
      "0.5995492935180664 0.7920353456067741 0.7399819431904993\n",
      "0.5994475483894348 0.792029823917579 0.7400513924578096\n",
      "0.5993409752845764 0.7919877741306312 0.7401902909924302\n",
      "0.5992383360862732 0.791970784317723 0.7402597402597403\n",
      "0.59913569688797 0.7919571924673965 0.7401208417251198\n",
      "0.5990333557128906 0.7919486975609424 0.7403291895270505\n",
      "0.5989315509796143 0.7919635636472371 0.7403291895270505\n",
      "0.5988300442695618 0.7918340163238122 0.7405722619626364\n",
      "0.5987290143966675 0.7918183007468722 0.7399472185568443\n",
      "0.5986286997795105 0.7918144780389679 0.7400861170914647\n",
      "0.598638653755188 0.7918306183612306 0.7398777692895341\n",
      "0.5986171960830688 0.7917558631844346 0.7400861170914648\n",
      "0.5983985662460327 0.7917477930233032 0.7402944648933953\n",
      "0.5982679724693298 0.7917384486262038 0.7402250156260851\n",
      "0.5981617569923401 0.791730803210395 0.7406417112299466\n",
      "0.5980648994445801 0.7917163618694232 0.7402597402597403\n",
      "0.5979720950126648 0.7917070174723237 0.740468088061671\n",
      "0.5978817343711853 0.791719335086682 0.740468088061671\n",
      "0.5977914333343506 0.791742271334108 0.7408847836655325\n",
      "0.5977014899253845 0.7917295289744269 0.741093131467463\n",
      "0.5976120829582214 0.7917248567758772 0.741093131467463\n",
      "0.597523033618927 0.7916925761313516 0.741370928536704\n",
      "0.5974343419075012 0.7916823822436068 0.7413709285367039\n",
      "0.5973460674285889 0.7916543490523082 0.7414403778040142\n",
      "0.5972582101821899 0.7916484026177903 0.7415792763386346\n",
      "0.5971709489822388 0.7916585965055353 0.7415098270713244\n",
      "0.5970839262008667 0.7916339612768185 0.7415098270713243\n",
      "0.5969980955123901 0.791663268704085 0.7414403778040142\n",
      "0.5970606207847595 0.7917286794837816 0.7409195082991875\n",
      "0.5969861149787903 0.7916207941718145 0.7415792763386346\n",
      "0.5967800617218018 0.7916607202321488 0.7417181748732551\n",
      "0.5966700315475464 0.791667516157312 0.7411278561011182\n",
      "0.5965890884399414 0.7916607202321488 0.7409889575664977\n",
      "0.5965113639831543 0.7916679409026348 0.741058406833808\n",
      "0.5964303016662598 0.791670489374571 0.7409542329328427\n",
      "0.5963512659072876 0.7916441551645634 0.7408847836655323\n",
      "0.596272349357605 0.7916033796135837 0.7408847836655323\n",
      "0.5961938500404358 0.7916046538495518 0.7408500590318772\n",
      "0.596115231513977 0.791608901302779 0.7408500590318772\n",
      "0.5960366129875183 0.791617396209233 0.7409195082991875\n",
      "0.5959579348564148 0.7916195199358464 0.740780609764567\n",
      "0.5958788394927979 0.7916556232882764 0.7409195082991875\n",
      "0.5957993865013123 0.7916785595357024 0.741058406833808\n",
      "0.5957193374633789 0.7917359001542674 0.7405028126953261\n",
      "0.5956388115882874 0.7917048937457101 0.7405375373289813\n",
      "0.5955805778503418 0.7917405723528173 0.7406764358636017\n",
      "0.5955058336257935 0.7917545889484665 0.7403291895270505\n",
      "0.5954843759536743 0.7917656323268567 0.7403986387943607\n",
      "0.5953395962715149 0.7918081068591273 0.7403291895270505\n",
      "0.595249354839325 0.7917520404765304 0.7401902909924301\n",
      "0.5951789021492004 0.7917749767239564 0.7401555663587749\n",
      "0.5951022505760193 0.7918344410691349 0.7400513924578096\n",
      "0.5950303673744202 0.7918378390317167 0.7393916244183625\n",
      "0.5949583649635315 0.791850156646075 0.7392527258837419\n",
      "0.5948874950408936 0.7918637484964016 0.7393916244183625\n",
      "0.5948171019554138 0.7919219386056121 0.7391485519827766\n",
      "0.5947471857070923 0.7919436006170701 0.7389402041808459\n",
      "0.5946776866912842 0.7919661121191732 0.7389402041808459\n",
      "0.5946085453033447 0.7919805534601453 0.7390096534481562\n",
      "0.5945398211479187 0.7919206643696439 0.7390791027154664\n",
      "0.5944711565971375 0.7919648378832054 0.7392180012500867\n",
      "0.5944036841392517 0.7919971185277308 0.7394263490520175\n",
      "0.5944800972938538 0.7920132588499935 0.739565247586638\n",
      "0.5944247841835022 0.7919826771867587 0.7392874505173971\n",
      "0.5942142605781555 0.7920136835953162 0.7394610736856726\n",
      "0.5941454172134399 0.7920217537564476 0.7397041461212585\n",
      "0.5940865278244019 0.7920489374571007 0.739843044655879\n",
      "0.5940179824829102 0.7920803686109809 0.7397735953885687\n",
      "0.5939542651176453 0.7921109502742156 0.7397735953885687\n",
      "0.5938916802406311 0.7920969336785663 0.7399819431904994\n",
      "0.5938291549682617 0.7920999068958252 0.7401208417251198\n",
      "0.5937667489051819 0.7919843761680496 0.7400513924578096\n",
      "0.5937045812606812 0.792002640216926 0.7400513924578096\n",
      "0.59364253282547 0.7919393531638429 0.7400513924578096\n",
      "0.5935805439949036 0.7919431758717473 0.7401902909924301\n",
      "0.5935187935829163 0.7919618646659463 0.7403986387943607\n",
      "0.5934569239616394 0.7919610151753009 0.7405375373289812\n",
      "0.5933952927589417 0.791976730752241 0.7406417112299466\n",
      "0.5933337211608887 0.7920022154716032 0.740780609764567\n",
      "0.59327232837677 0.7920302486629017 0.7408500590318773\n",
      "0.5932255387306213 0.792041292041292 0.7409195082991875\n",
      "0.5932892560958862 0.792064228288718 0.7407806097645669\n",
      "0.5931897163391113 0.7920897130080803 0.7409195082991875\n",
      "0.5930479764938354 0.7921058533303431 0.7409195082991874\n",
      "0.5929779410362244 0.7921105255288929 0.7408500590318773\n",
      "0.5929232835769653 0.7921377092295458 0.7409195082991875\n",
      "0.5928651094436646 0.7921738125819758 0.7409195082991875\n",
      "0.5928066372871399 0.7921916518855293 0.7405028126953261\n",
      "0.5927495956420898 0.7921483278626136 0.7405375373289811\n",
      "0.5926922559738159 0.7921772105445575 0.7405028126953261\n",
      "0.5926350355148315 0.7921687156381034 0.7404333634280159\n",
      "0.5925778746604919 0.7921279400871237 0.7403639141607057\n",
      "0.5925204753875732 0.792167866147458 0.7405722619626364\n",
      "0.592462956905365 0.7922009962826289 0.7405722619626363\n",
      "0.5924052000045776 0.7922082169531148 0.740780609764567\n",
      "0.5923473834991455 0.7922434708148994 0.7409889575664976\n",
      "0.5922892689704895 0.792266831807648 0.740780609764567\n",
      "0.5922309756278992 0.7922927412723332 0.7405028126953261\n",
      "0.5921722054481506 0.7923241724262132 0.7405375373289811\n",
      "0.592113196849823 0.7923640984865475 0.7402944648933953\n",
      "0.5920826196670532 0.7923844862620373 0.7402944648933955\n",
      "0.59200519323349 0.7924303587568894 0.7402250156260852\n",
      "0.5920243859291077 0.7924439506072158 0.7400861170914647\n",
      "0.5919144749641418 0.7924838766675502 0.7402250156260851\n",
      "0.5918301343917847 0.7924702848172236 0.7406417112299466\n",
      "0.5917695164680481 0.7923292693700856 0.7406417112299465\n",
      "0.5917142033576965 0.7923883089699415 0.7405722619626364\n",
      "0.5916559100151062 0.7923968038763958 0.7407806097645669\n",
      "0.5915992259979248 0.792407847254786 0.7406417112299466\n",
      "0.5915422439575195 0.792406573018818 0.740502812695326\n",
      "0.5914853811264038 0.7924545692402836 0.7405375373289812\n",
      "0.5914285182952881 0.7924961942819087 0.7403291895270505\n",
      "0.5913717746734619 0.7925246522185296 0.7403291895270505\n",
      "0.5913147926330566 0.792553110155151 0.740468088061671\n",
      "0.5912578701972961 0.7925603308256369 0.7405375373289812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5912009477615356 0.7925539596457963 0.7405375373289812\n",
      "0.5911443829536438 0.7925297491624022 0.7406764358636017\n",
      "0.5910918116569519 0.792482602431582 0.7403639141607056\n",
      "0.591414213180542 0.7925437657580514 0.7393568997847072\n",
      "0.5910386443138123 0.7924855756488409 0.7404333634280158\n",
      "0.5909735560417175 0.7925284749264342 0.7401555663587749\n",
      "0.5908786654472351 0.7925059634243308 0.7391485519827766\n",
      "0.5908300280570984 0.792538668814179 0.7390791027154664\n",
      "0.5907774567604065 0.7925569328630553 0.7392180012500869\n",
      "0.590726912021637 0.7926074775564571 0.7393568997847072\n",
      "0.5906770825386047 0.7926142734816204 0.7393568997847072\n",
      "0.5906282663345337 0.7925484379566012 0.7393568997847073\n",
      "0.590579628944397 0.7925785948745132 0.7392874505173971\n",
      "0.590531051158905 0.7926129992456523 0.7394263490520175\n",
      "0.5904831290245056 0.7926342365117875 0.7392874505173971\n",
      "0.5904352068901062 0.792616397208234 0.7390791027154664\n",
      "0.5903875231742859 0.7926274405866243 0.7388707549135356\n",
      "0.5903400182723999 0.792672463590831 0.7390791027154664\n",
      "0.590292751789093 0.7927034699993883 0.7390096534481562\n",
      "0.590247392654419 0.792724282520201 0.7391485519827766\n",
      "0.5903555750846863 0.7926516510700184 0.7392874505173971\n",
      "0.590256929397583 0.7924520207683473 0.7394263490520175\n",
      "0.5901249647140503 0.7925437657580514 0.7392180012500867\n",
      "0.5900806188583374 0.7925798691104814 0.7394263490520175\n",
      "0.59002286195755 0.7926257416053335 0.7392874505173971\n",
      "0.589978814125061 0.7926440056542097 0.7393916244183625\n",
      "0.5899346470832825 0.7926563232685682 0.7394610736856726\n",
      "0.5898903012275696 0.7925620298069278 0.7395305229529828\n",
      "0.5898469090461731 0.7925773206385451 0.739565247586638\n",
      "0.5898034572601318 0.7926045043391982 0.739565247586638\n",
      "0.5897602438926697 0.7926214941521064 0.7394957983193278\n",
      "0.5897172093391418 0.7926384839650146 0.7394263490520175\n",
      "0.5896742343902588 0.7926554737779228 0.7394263490520175\n",
      "0.5896314978599548 0.7925407925407926 0.7394263490520175\n",
      "0.5895887613296509 0.7925395183048244 0.7397735953885687\n",
      "0.5895473957061768 0.7925590565896687 0.7397735953885687\n",
      "0.5896459221839905 0.7925089366415896 0.7396346968539482\n",
      "0.5895817279815674 0.7925624545522505 0.7399124939231891\n",
      "0.5894338488578796 0.7924745322704507 0.7398430446558788\n",
      "0.5894033908843994 0.7924770807423869 0.7399819431904993\n",
      "0.5893429517745972 0.7924647631280285 0.7401208417251197\n",
      "0.5893062949180603 0.7924775054877096 0.7401208417251199\n",
      "0.5892640948295593 0.7925004417351356 0.7401902909924301\n",
      "0.5892246961593628 0.792501291225781 0.7402597402597403\n",
      "0.5891854763031006 0.7925407925407926 0.7402597402597402\n",
      "0.5891463756561279 0.7925437657580514 0.74019029099243\n",
      "0.5891072154045105 0.7925484379566012 0.7401208417251197\n",
      "0.5890684127807617 0.7925726484399953 0.7401208417251198\n",
      "0.5890297889709473 0.7925849660543539 0.7403291895270505\n",
      "0.5889911651611328 0.7926011063766165 0.7402597402597403\n",
      "0.5889526605606079 0.792636360238401 0.7403986387943607\n",
      "0.5889143347740173 0.7926457046355004 0.7406069865962914\n",
      "0.5888797044754028 0.7926660924109903 0.7407458851309119\n",
      "0.5891014337539673 0.7925773206385451 0.7406764358636017\n",
      "0.5889249444007874 0.7927357506439139 0.7405722619626364\n",
      "0.5887654423713684 0.7927174865950377 0.7406069865962914\n",
      "0.5887457728385925 0.7927162123590695 0.7405028126953261\n",
      "0.5886940956115723 0.7927433960597225 0.740502812695326\n",
      "0.5886594653129578 0.7927425465690772 0.7403986387943607\n",
      "0.5886234045028687 0.7927633590898897 0.7403291895270505\n",
      "0.5885873436927795 0.7928062583674829 0.7403986387943607\n",
      "0.588551938533783 0.7927977634610288 0.7403291895270505\n",
      "0.5885168313980103 0.7928325925774906 0.7403291895270505\n",
      "0.5884817838668823 0.7928355657947495 0.7402597402597403\n",
      "0.5884469747543335 0.7928678464392751 0.7402597402597403\n",
      "0.5884122252464294 0.7928733681284701 0.7401902909924301\n",
      "0.5883774161338806 0.7928861104881513 0.7401208417251198\n",
      "0.5883429050445557 0.7927994624423196 0.7399124939231891\n",
      "0.5883089303970337 0.7928402379932993 0.7399124939231891\n",
      "0.5883203148841858 0.7928313183415225 0.7399819431904995\n",
      "0.5882565379142761 0.7928308935961996 0.7397041461212585\n",
      "0.588268518447876 0.792879314562988 0.7397735953885687\n",
      "0.5881773233413696 0.7928508566263668 0.7398430446558789\n",
      "0.5881524085998535 0.7928631742407253 0.739843044655879\n",
      "0.5881113409996033 0.792926886039131 0.7399124939231891\n",
      "0.5880797505378723 0.7929383541628439 0.7399819431904994\n",
      "0.588047444820404 0.7929561934663976 0.7400513924578096\n",
      "0.5880152583122253 0.7929625646462382 0.7400513924578097\n",
      "0.5879834294319153 0.7929863503843095 0.7401902909924301\n",
      "0.5879516005516052 0.7928733681284701 0.7400513924578096\n",
      "0.587920069694519 0.7928937559039599 0.7400513924578096\n",
      "0.5878883600234985 0.7929005518291232 0.7399819431904994\n",
      "0.5878570079803467 0.7929098962262228 0.7400513924578096\n",
      "0.5878255367279053 0.792919665368645 0.7401208417251198\n",
      "0.5877941250801086 0.7929515212678477 0.7401902909924301\n",
      "0.5877628922462463 0.7929600161743019 0.7402597402597403\n",
      "0.5877349376678467 0.7929761564965647 0.7403986387943607\n",
      "0.5879462361335754 0.793084891299177 0.7403291895270505\n",
      "0.5878015756607056 0.7929370799268758 0.740468088061671\n",
      "0.5876415371894836 0.7928903579413784 0.740468088061671\n",
      "0.5876286625862122 0.792905224027673 0.740468088061671\n",
      "0.5875816345214844 0.7929553439757522 0.740468088061671\n",
      "0.5875542163848877 0.7929757317512419 0.7403986387943609\n",
      "0.587523341178894 0.7930122598489946 0.7403291895270506\n",
      "0.5874935984611511 0.7929905978375366 0.7402597402597403\n",
      "0.5874641537666321 0.7930211795007713 0.7402597402597403\n",
      "0.5874348878860474 0.7930016412159269 0.7400513924578096\n",
      "0.5874055624008179 0.7930385940590021 0.7399124939231891\n",
      "0.5873762369155884 0.7929536449944613 0.7397735953885687\n",
      "0.5873469114303589 0.7929821029310826 0.7398430446558789\n",
      "0.5873176455497742 0.7930233032273848 0.7399124939231891\n",
      "0.5872883796691895 0.7930394435496476 0.7400513924578097\n",
      "0.5872589349746704 0.7930955099322445 0.7401208417251198\n",
      "0.58722984790802 0.7931027306027305 0.7401208417251198\n",
      "0.5872198343276978 0.7931995725363072 0.7401208417251198\n",
      "0.5874028205871582 0.7931562485133914 0.7401208417251198\n",
      "0.5871541500091553 0.7932046694801796 0.7400513924578097\n",
      "0.5871390700340271 0.793169840363718 0.7400513924578097\n",
      "0.5870952606201172 0.7931872549219487 0.7400861170914648\n",
      "0.5870612859725952 0.7930916872243403 0.7401208417251198\n",
      "0.5870331525802612 0.7931621949479093 0.7401208417251198\n",
      "0.5870048403739929 0.7931719640903314 0.7400861170914648\n",
      "0.5869765877723694 0.7932216592930879 0.7402944648933953\n",
      "0.5869488716125488 0.7932484182484183 0.7403986387943606\n",
      "0.5869211554527283 0.7932556389189043 0.7402944648933953\n",
      "0.5868934392929077 0.7932713544958443 0.7402944648933953\n",
      "0.5868655443191528 0.7932913175260115 0.7402944648933955\n",
      "0.5868379473686218 0.7932968392152067 0.7403639141607057\n",
      "0.586810290813446 0.7932679565332627 0.7403639141607057\n",
      "0.5867828130722046 0.7932764514397168 0.7402597402597403\n",
      "0.5867551565170288 0.7933218991892461 0.7401555663587749\n",
      "0.586728036403656 0.7933231734252142 0.7400513924578097\n",
      "0.586724042892456 0.7929697853167241 0.7400861170914648\n",
      "0.5868610143661499 0.7929081972449319 0.7400513924578096\n",
      "0.5866842865943909 0.7929999422346361 0.7400513924578096\n",
      "0.5866299271583557 0.7932666822972945 0.7400513924578095\n",
      "0.5866089463233948 0.793146479370969 0.7403986387943607\n",
      "0.586570680141449 0.7930394435496476 0.7402250156260851\n",
      "0.5865468382835388 0.7930657777596553 0.7403291895270505\n",
      "0.5865198373794556 0.7930780953740137 0.7406069865962914\n",
      "0.5864948630332947 0.7930789448646591 0.7406764358636017\n",
      "0.5864694714546204 0.7930861655351451 0.7406069865962914\n",
      "0.5864442586898804 0.7929680863354334 0.7406417112299466\n",
      "0.5864192247390747 0.7929995174893134 0.7406417112299466\n",
      "0.5863942503929138 0.7929939958001182 0.7407806097645669\n",
      "0.5863692760467529 0.7930466642201336 0.7407111604972568\n",
      "0.5863444805145264 0.7930759716474002 0.7407111604972568\n",
      "0.5863196849822998 0.7930857407898224 0.7407458851309119\n",
      "0.5862950682640076 0.7931014563667625 0.7408153343982221\n",
      "0.5862704515457153 0.7931171719437026 0.740780609764567\n",
      "0.5862458348274231 0.7931562485133914 0.740780609764567\n",
      "0.5862215757369995 0.7931889539032397 0.740780609764567\n",
      "0.586235761642456 0.7932479935030956 0.740780609764567\n",
      "0.5862202644348145 0.7932862205821389 0.7408153343982221\n",
      "0.5862461924552917 0.7933342168036046 0.740780609764567\n",
      "0.5861389636993408 0.7932823978742347 0.740780609764567\n",
      "0.5861057043075562 0.7932705050051989 0.7408153343982221\n",
      "0.5860864520072937 0.7932832473648801 0.7408153343982221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5860607624053955 0.793290468035366 0.7408153343982221\n",
      "0.5860379338264465 0.7933592767776441 0.7406069865962915\n",
      "0.586015522480011 0.7933690459200664 0.7406069865962915\n",
      "0.5859932899475098 0.7933673469387755 0.7405722619626363\n",
      "0.5859710574150085 0.7933970791113649 0.7406069865962915\n",
      "0.5859490633010864 0.7934004770739465 0.7406069865962914\n",
      "0.5859271287918091 0.7934229885760498 0.740745885130912\n",
      "0.585905134677887 0.7934357309357309 0.740745885130912\n",
      "0.5858833193778992 0.7934459248234758 0.7407111604972568\n",
      "0.5858615636825562 0.7934590919284796 0.740780609764567\n",
      "0.5858398079872131 0.7934586671831569 0.7405722619626363\n",
      "0.5858181118965149 0.79347013530687 0.7405375373289812\n",
      "0.585796594619751 0.7934773559773559 0.7392527258837419\n",
      "0.5857749581336975 0.7934735332694516 0.7393221751510521\n",
      "0.5857535600662231 0.7933677716840982 0.7392527258837419\n",
      "0.5857320427894592 0.7933724438826479 0.7391138273491216\n",
      "0.5857111215591431 0.7933788150624885 0.7392180012500869\n",
      "0.5857435464859009 0.7935134593297859 0.7389402041808459\n",
      "0.5856696963310242 0.7934246875573405 0.739252725883742\n",
      "0.585725724697113 0.7935185562736583 0.7391138273491216\n",
      "0.5856658816337585 0.7934030255458827 0.7391138273491216\n",
      "0.5856192111968994 0.7934208648494363 0.7391138273491216\n",
      "0.5855903625488281 0.7934782054680014 0.7391832766164317\n",
      "0.585570216178894 0.7932348263980917 0.7391832766164317\n",
      "0.5855512022972107 0.793238649105996 0.7392527258837419\n",
      "0.5855310559272766 0.7932318531808328 0.7393221751510521\n",
      "0.5855117440223694 0.7932280304729284 0.7393221751510521\n",
      "0.5854922533035278 0.7932509667203544 0.7392874505173971\n",
      "0.5854730010032654 0.7932530904469681 0.739287450517397\n",
      "0.5854537487030029 0.7932679565332627 0.7393221751510521\n",
      "0.5854344964027405 0.7932756019490713 0.7393916244183625\n",
      "0.585415244102478 0.793145205135001 0.7393916244183625\n",
      "0.5853961110115051 0.7931936261017893 0.7395305229529829\n",
      "0.5853768587112427 0.7931804589967855 0.7395305229529829\n",
      "0.5853579044342041 0.7931813084874308 0.7395999722202931\n",
      "0.5853387117385864 0.7931821579780763 0.7395305229529829\n",
      "0.5853197574615479 0.7931978735550165 0.7395305229529829\n",
      "0.5853006839752197 0.7931766362888812 0.7395305229529829\n",
      "0.5852816700935364 0.7931868301766261 0.7395999722202931\n",
      "0.5852625966072083 0.7931817332327536 0.7395305229529828\n",
      "0.5852436423301697 0.7931787600154947 0.7395999722202931\n",
      "0.5852245688438416 0.7931791847608174 0.7396694214876033\n",
      "0.5852056741714478 0.7932322779261555 0.7397041461212583\n",
      "0.5851877331733704 0.7932377996153508 0.7396694214876033\n",
      "0.58542799949646 0.793201271517598 0.7384540593096742\n",
      "0.5854231119155884 0.7930623797970737 0.7397388707549135\n",
      "0.5852222442626953 0.7933673469387754 0.7398083200222239\n",
      "0.5851360559463501 0.7933282703690867 0.739877769289534\n",
      "0.585100531578064 0.79326753178794 0.739877769289534\n",
      "0.585080623626709 0.7932794246569757 0.7398083200222239\n",
      "0.5850632190704346 0.7932739029677806 0.7398083200222239\n",
      "0.585046112537384 0.7932798494022983 0.7401208417251198\n",
      "0.585028886795044 0.7933928316581378 0.7402597402597403\n",
      "0.5850117802619934 0.793389433695556 0.7402597402597402\n",
      "0.5849946141242981 0.7933996275833011 0.7403291895270505\n",
      "0.5849775075912476 0.7932666822972945 0.7403639141607056\n",
      "0.5849604606628418 0.7932794246569757 0.7391138273491215\n",
      "0.5849434733390808 0.7932590368814859 0.7390791027154664\n",
      "0.584926426410675 0.7932683812785853 0.7389054795471908\n",
      "0.5849093794822693 0.7932760266943941 0.7387665810125703\n",
      "0.5848925113677979 0.7932632843347129 0.7386971317452602\n",
      "0.7417181748732551 0.7585933966530982\n"
     ]
    }
   ],
   "source": [
    "best=0\n",
    "wh=0\n",
    "for epoch in range(num_epoch):\n",
    "    out=model(x_train)\n",
    "    loss=criterion(out,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print_loss=loss.data.item()\n",
    "    train_auc=roc_auc_score(y_train,out.detach().numpy())\n",
    "    out_valid=model(x_valid)\n",
    "    valid_auc=roc_auc_score(y_valid,out_valid.detach().numpy())\n",
    "    \n",
    "    if(valid_auc>best):\n",
    "        best=valid_auc\n",
    "        wh=epoch\n",
    "        torch.save({'model_state_dict': model.state_dict()},task+'local_best_model.pth')\n",
    "    if(epoch%10==0):\n",
    "        print(print_loss,train_auc,valid_auc)\n",
    "model.load_state_dict(torch.load(task+'local_best_model.pth')['model_state_dict'])\n",
    "out_test=model(x_test)\n",
    "test_auc=roc_auc_score(y_test,out_test.detach().numpy())\n",
    "print(best,test_auc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
